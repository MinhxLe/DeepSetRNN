{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data import school_contact, set_seq, math_tags\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import logging\n",
    "import os\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:starting logger\n"
     ]
    }
   ],
   "source": [
    "logging.info(\"starting logger\")\n",
    "_LOGGER = logging.getLogger('seq_model')\n",
    "_LOGGER.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_name = 'school_contact'\n",
    "data_module = importlib.import_module('src.data.{}'.format(data_name))\n",
    "full_seq_path = os.path.join('data/raw/', data_module.DIR_NAME, data_module.FNAME)\n",
    "sequences = set_seq.get_sequences(full_seq_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:set_seq:Loss at epo 0: 4.311351221986115e-05\n",
      "INFO:set_seq:Loss at epo 1: 4.202735726721585e-05\n",
      "INFO:set_seq:Loss at epo 2: 4.1100720409303904e-05\n",
      "INFO:set_seq:Loss at epo 3: 4.0304206777364016e-05\n",
      "INFO:set_seq:Loss at epo 4: 3.963306880905293e-05\n",
      "INFO:set_seq:Loss at epo 5: 3.902919343090616e-05\n",
      "INFO:set_seq:Loss at epo 6: 3.84349659725558e-05\n",
      "INFO:set_seq:Loss at epo 7: 3.781956547754817e-05\n",
      "INFO:set_seq:Loss at epo 8: 3.717962317750789e-05\n",
      "INFO:set_seq:Loss at epo 9: 3.654411921161227e-05\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'embedding_dims' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-240eb00945d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mW1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mW2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mW_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'data/processed/{}_embedding_normalized_d{}.pt'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding_dims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'embedding_dims' is not defined"
     ]
    }
   ],
   "source": [
    "#pretraining embedding\n",
    "pairs = []\n",
    "for sequence in sequences:\n",
    "    for seq_set in sequence:\n",
    "        for i in range(len(seq_set)):\n",
    "            for j in range(i+1, len(seq_set)):\n",
    "                pairs.append((seq_set[i],seq_set[j]))\n",
    "EMBEDDING_DIM = 5 \n",
    "W1,W2 = set_seq.generate_embedding(pairs, school_contact.N_ELEMENTS, embedding_dims=EMBEDDING_DIM, n_epoch=10)\n",
    "W = W1.t().data+W2.data\n",
    "W_norm = W.div(torch.norm(W,dim=1).view(-1,1))\n",
    "torch.save(W_norm, 'data/processed/{}_embedding_normalized_d{}.pt'.format(data_name, EMBEDDING_DIM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting 1 hot representation of sequences\n",
    "#for each sequence with length N, you will have a corresponding tensor with shaep N by N_ELEMENTS representing set of sequences\n",
    "one_hot_sequences = []\n",
    "for sequence in sequences:\n",
    "    one_hot_sequences.append(torch.cat([torch.zeros(1, data_module.N_ELEMENTS, dtype=torch.float).\\\n",
    "     scatter(1, torch.LongTensor(elm_set).view(1,-1), 1) for elm_set in sequence]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model.set_sequence import SetSequenceModel\n",
    "\n",
    "embedding = W_norm\n",
    "HIDDEN_DIM = 100\n",
    "EMBEDDING_DIM = 5\n",
    "model = SetSequenceModel(hidden_dim=HIDDEN_DIM,\n",
    "                         n_class=data_module.N_ELEMENTS,\n",
    "                         embedding=embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_seq = 100\n",
    "\n",
    "split = int(n_seq*0.8)\n",
    "train_sequences = sequences[:split]\n",
    "train_targets =  one_hot_sequences[:split]\n",
    "\n",
    "test_sequences = sequences[split:n_seq]\n",
    "test_targets = one_hot_sequences[split:n_seq]\n",
    "\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:seq_model:Validation Loss: 0.6921250224113464\n"
     ]
    }
   ],
   "source": [
    "test_losses = []\n",
    "for sequence, target in zip(test_sequences, test_targets):\n",
    "    model.hidden = model.init_hidden()\n",
    "    logits = model(sequence)\n",
    "    loss = loss_fn(logits[1:].view(-1),target[1:].view(-1))\n",
    "    test_losses.append(loss.data)\n",
    "_LOGGER.info(\"Validation Loss: {}\".format(np.mean(test_losses)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:seq_model:epoch 0: 0.6434968709945679\n",
      "DEBUG:seq_model:epoch 1: 0.25893163681030273\n",
      "DEBUG:seq_model:epoch 2: 0.052015483379364014\n",
      "DEBUG:seq_model:epoch 3: 0.04151865467429161\n",
      "DEBUG:seq_model:epoch 4: 0.038553621619939804\n",
      "DEBUG:seq_model:epoch 5: 0.03725401312112808\n",
      "DEBUG:seq_model:epoch 6: 0.03657124564051628\n",
      "DEBUG:seq_model:epoch 7: 0.03617190569639206\n",
      "DEBUG:seq_model:epoch 8: 0.03592048957943916\n",
      "DEBUG:seq_model:epoch 9: 0.03575325757265091\n",
      "DEBUG:seq_model:epoch 10: 0.035637058317661285\n",
      "DEBUG:seq_model:epoch 11: 0.03555335849523544\n",
      "DEBUG:seq_model:epoch 12: 0.035491183400154114\n",
      "DEBUG:seq_model:epoch 13: 0.0354437455534935\n",
      "DEBUG:seq_model:epoch 14: 0.03540666401386261\n",
      "DEBUG:seq_model:epoch 15: 0.035377055406570435\n",
      "DEBUG:seq_model:epoch 16: 0.03535294532775879\n",
      "DEBUG:seq_model:epoch 17: 0.03533295542001724\n",
      "DEBUG:seq_model:epoch 18: 0.035316117107868195\n",
      "DEBUG:seq_model:epoch 19: 0.035301707684993744\n",
      "DEBUG:seq_model:epoch 20: 0.0352892205119133\n",
      "DEBUG:seq_model:epoch 21: 0.03527825325727463\n",
      "DEBUG:seq_model:epoch 22: 0.035268522799015045\n",
      "DEBUG:seq_model:epoch 23: 0.035259783267974854\n",
      "DEBUG:seq_model:epoch 24: 0.03525187075138092\n",
      "DEBUG:seq_model:epoch 25: 0.035244643688201904\n",
      "DEBUG:seq_model:epoch 26: 0.03523799031972885\n",
      "DEBUG:seq_model:epoch 27: 0.035231828689575195\n",
      "DEBUG:seq_model:epoch 28: 0.03522607684135437\n",
      "DEBUG:seq_model:epoch 29: 0.0352206826210022\n",
      "DEBUG:seq_model:epoch 30: 0.0352155975997448\n",
      "DEBUG:seq_model:epoch 31: 0.035210780799388885\n",
      "DEBUG:seq_model:epoch 32: 0.035206206142902374\n",
      "DEBUG:seq_model:epoch 33: 0.03520183265209198\n",
      "DEBUG:seq_model:epoch 34: 0.03519764542579651\n",
      "DEBUG:seq_model:epoch 35: 0.03519362211227417\n",
      "DEBUG:seq_model:epoch 36: 0.03518974035978317\n",
      "DEBUG:seq_model:epoch 37: 0.03518600016832352\n",
      "DEBUG:seq_model:epoch 38: 0.03518236428499222\n",
      "DEBUG:seq_model:epoch 39: 0.03517884016036987\n",
      "DEBUG:seq_model:epoch 40: 0.03517540916800499\n",
      "DEBUG:seq_model:epoch 41: 0.03517206758260727\n",
      "DEBUG:seq_model:epoch 42: 0.03516879677772522\n",
      "DEBUG:seq_model:epoch 43: 0.03516559675335884\n",
      "DEBUG:seq_model:epoch 44: 0.03516245633363724\n",
      "DEBUG:seq_model:epoch 45: 0.03515937551856041\n",
      "DEBUG:seq_model:epoch 46: 0.03515633940696716\n",
      "DEBUG:seq_model:epoch 47: 0.0351533442735672\n",
      "DEBUG:seq_model:epoch 48: 0.03515038639307022\n",
      "DEBUG:seq_model:epoch 49: 0.03514745831489563\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=.9)\n",
    "losses = []\n",
    "n_epoch = 50\n",
    "\n",
    "for epoch in range(n_epoch):\n",
    "    curr_losses = []\n",
    "    for sequence, target in zip(train_sequences,\n",
    "                                train_targets):\n",
    "        model.zero_grad()\n",
    "        model.hidden = model.init_hidden()\n",
    "        \n",
    "        logits = model(sequence)\n",
    "        loss = loss_fn(logits[1:].view(-1),target[1:].view(-1))\n",
    "        curr_losses.append(loss.data)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    mean_loss = np.mean(curr_losses)\n",
    "    losses.append(mean_loss)\n",
    "    _LOGGER.debug(\"epoch {}: {}\".format(epoch, mean_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:seq_model:Validation Loss: 0.03241962939500809\n"
     ]
    }
   ],
   "source": [
    "test_losses = []\n",
    "for sequence, target in zip(test_sequences, test_targets):\n",
    "    model.hidden = model.init_hidden()\n",
    "    logits = model(sequence)\n",
    "    loss = loss_fn(logits[-1].view(-1),target[-1].view(-1))\n",
    "    test_losses.append(loss.data)\n",
    "_LOGGER.info(\"Validation Loss: {}\".format(np.mean(test_losses)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 10\n",
    "logits = model(test_sequences[i])\n",
    "prediction = torch.sigmoid(model(test_sequences[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[65], [65], [65], [40], [40], [65], [40], [65], [40], [40], [65], [65], [65], [65], [44], [65], [65], [45], [65], [65], [65], [65], [69, 45], [46], [68], [65, 44], [65], [65], [41], [45], [188, 41, 45], [46], [45], [65], [18], [65], [181], [45], [65], [65], [30, 65], [65], [65], [65], [30], [30], [30], [45], [45], [40], [45], [45], [45], [65], [45], [65, 45], [65], [40], [30], [30, 24], [30], [30], [44], [40], [188, 44], [188, 44], [30, 44], [30], [44], [65], [65], [65], [25, 65], [188, 18], [188], [40], [65], [65], [65], [65], [65], [45, 44], [65, 45], [65, 44], [65], [65, 45, 44], [65], [65], [65], [65], [65], [65], [65], [65, 45], [65], [65], [65], [181], [45], [45], [44], [45, 44], [45, 44], [65, 45], [45, 44], [65, 45, 44], [65, 45], [65], [65], [65, 44], [65, 44], [65], [65], [65, 44], [65, 44], [65], [45], [65], [45], [45], [65], [45], [42, 65, 68], [45, 181], [25], [25, 65], [25], [25], [18, 43], [46, 5], [46, 5], [46], [46], [52], [52], [46], [46], [46], [46], [46], [131, 5], [5], [107], [46], [68, 107, 45], [68], [68], [46], [46, 69], [46], [46], [178], [46], [46], [174], [166, 46], [46], [46, 30], [46], [182], [46], [46], [65], [65], [65], [65], [68], [65], [65], [65], [45], [65], [65, 45], [65], [65], [56], [56], [45], [45], [45], [45], [45], [44], [65], [65], [65], [65], [65], [45], [45], [45], [45], [65, 45], [65], [65], [65], [65], [65], [65, 44], [65], [65], [65], [65], [65, 181, 44], [65, 181], [45], [65], [65], [65], [65], [65], [65], [65, 44], [44], [65, 44], [65], [65], [65, 44], [65], [65, 44], [65], [65], [181], [65], [65], [65], [65], [65, 44], [65], [65], [65], [65], [45], [65], [65], [65], [65], [65], [46, 231], [18], [41, 231], [25, 41, 231], [231], [41, 231], [231], [30, 231], [44], [101], [30, 100], [184, 69], [219], [145, 136, 157], [145, 136], [124, 100], [8, 103, 90], [82], [86], [101], [101, 7, 137], [101, 7, 137], [101], [101], [101], [101], [101, 183], [166, 101], [156, 68], [221, 105], [55, 117], [166, 203, 105], [203], [203], [105], [203], [207, 181], [105], [105, 181], [203], [105], [105, 181], [207, 105], [203], [203, 105], [203, 105], [207, 203], [203, 105, 181], [105, 181], [181], [181], [105], [181], [203, 181], [181], [220], [181], [181], [203, 181], [203, 105], [105], [203], [203], [207], [203, 105], [207, 105], [105], [203], [105], [203, 105], [203, 105], [203, 105], [105, 181], [203, 105], [207, 203, 105], [101, 203], [203], [207, 203], [203], [101, 203], [101, 203], [203], [203], [203], [203], [203], [203], [203], [203], [203], [203], [203], [207, 203], [203], [203], [203], [203], [101], [203, 219], [101, 203], [101], [101, 203, 181], [203, 181], [203, 181], [101, 203, 219], [49], [49, 105, 83], [105, 181], [152], [203, 105], [101, 203, 105], [220, 203, 105], [207, 220, 203, 105], [207, 203], [203, 213], [203], [203], [203], [203], [203], [207], [207, 203, 105], [203], [207, 203], [207], [207, 105], [105], [207, 105], [203, 105], [203], [207, 105], [105], [207], [207], [54], [101], [101, 54], [203], [42], [124, 119], [124, 119], [124, 110], [124], [124], [124, 40], [124, 40], [207], [207], [136], [139], [233, 139, 45], [233, 226], [233], [233, 206], [233], [233, 15], [233, 210], [233], [233], [101, 157], [101], [101, 157], [233, 145], [145], [145], [8, 221, 233, 145], [233, 40], [233], [206], [219, 136, 204], [219, 204], [219, 136], [219, 136], [219, 136, 204], [136, 204], [204], [136], [219], [44], [219], [219], [219, 213, 136], [136], [54, 136], [136], [145], [42], [136], [136], [213, 136, 204], [136], [101], [101, 213, 136], [136, 204], [136], [136], [136], [136], [122], [63], [136], [136], [82, 136, 44], [221, 203, 136, 44], [136, 195], [136], [171, 136], [136, 110], [210, 136, 110], [49, 136, 195], [136], [152, 136], [136], [136], [136], [15, 136, 55], [136, 110], [136], [136], [136], [62, 98, 136], [98, 136, 45], [49, 98, 136, 45], [2, 136, 45], [136, 45], [136, 45], [25, 45], [30, 41, 182], [182], [41, 182], [69, 182], [25, 41], [41, 69, 182], [41], [65], [46], [41, 56, 182], [46], [46, 30, 69], [30, 65], [65], [65], [65], [65], [40], [45], [45], [45], [45], [45], [45], [65], [45, 44], [45], [46], [65], [68, 45], [45], [45], [45], [45], [65], [45], [45], [45], [45], [45], [65], [65], [65], [65], [65], [65], [65], [65], [65], [65], [65], [65], [65], [65], [65], [40], [44], [40], [40], [65], [65], [65], [65], [65], [65], [65], [65], [65], [65], [65], [65], [65], [65], [65], [65], [65], [65], [65], [65], [65], [65], [65], [65], [45], [184], [42, 30], [30, 65], [30, 65], [231], [231], [30, 65], [17], [99], [68, 43], [152], [18, 56], [56], [231, 182], [18, 231], [18, 181], [231], [46], [41], [41], [41], [25, 18], [68], [68, 69], [43], [42], [24, 231], [45], [42, 46, 17], [65, 44], [42, 46, 65], [5], [17], [56], [233], [17], [17], [233, 17], [233, 41, 45, 17], [65], [65], [65], [65], [46], [30], [30], [30], [30], [30], [30, 65], [30], [65], [65], [65], [65, 18], [65], [181], [65], [181, 17], [65], [65], [65], [40], [40], [240], [42, 40], [184, 181], [181], [181], [181], [181], [181], [181], [231], [181], [45], [65, 45], [68], [46], [45, 182], [46], [46], [45, 181], [45], [45], [30], [30], [30], [30, 188], [30, 188], [45], [181], [181], [65], [65], [65], [65], [65], [181], [45], [181], [181], [69], [43], [181], [181], [181], [56, 182], [46, 18, 56], [69], [46], [18], [155, 69], [45], [44, 233, 17], [46, 233], [46, 44], [233, 17], [17], [233], [17], [233], [233], [236, 44], [233, 17], [17], [233, 184, 17], [184], [184], [184], [233], [233, 17], [46, 65], [18, 43, 56], [231, 181], [181], [181], [181], [181], [181], [181], [181], [181], [181], [181], [181], [181], [181], [181], [181], [181], [181], [181], [181], [181], [181], [65], [43], [43], [18, 17], [220], [176], [97], [97], [119], [65], [65, 69], [65, 69], [182], [46], [46, 233], [46], [46], [231, 56], [43], [56], [65, 43], [80], [65], [233], [181], [65], [45], [45], [233], [45], [45], [233], [46], [46, 17], [46, 17], [65, 233, 43], [65], [65, 233, 43], [65, 43], [162, 65], [43], [169], [40, 45], [17], [233], [233], [43], [43], [41, 136], [140], [119, 139, 129], [175], [46, 4], [46], [233], [73], [46, 24], [181], [181], [181], [181], [181], [45], [68, 184], [69], [181], [68], [184, 69]]\n"
     ]
    }
   ],
   "source": [
    "print(test_sequences[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 25, 234,  95, 121,  89],\n",
       "       [ 25,  95, 234, 177, 205],\n",
       "       [ 25,  95,  76, 234, 164],\n",
       "       ...,\n",
       "       [ 76,  25, 240, 237,  95],\n",
       "       [ 76,  25, 240, 237,  95],\n",
       "       [ 76,  25, 240, 237, 177]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argsort(prediction.data.numpy(),axis=1)[:,:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepset",
   "language": "python",
   "name": "deepset"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
