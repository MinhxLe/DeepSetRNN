{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/minh/Research/Sriram/DeepSetRNN\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%cd ~/Research/Sriram/DeepSetRNN\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import os\n",
    "import string\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import logging\n",
    "import os\n",
    "import importlib\n",
    "\n",
    "from src import convert_dot_format\n",
    "\n",
    "DATA_PATH='data/MIMIC3database'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(\"starting logger\")\n",
    "_LOGGER = logging.getLogger('MIMIC_seq_model')\n",
    "_LOGGER.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnoses_procedures_df = pd.read_csv('data/MIMIC3database/processed/ICD9_diagnoses_procedures_mimic_idx_sentences.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#only retaining top 100 diagnoses\n",
    "diagnoses_counts = diagnoses_procedures_df['ICD9_CODE_diagnoses'].value_counts()\n",
    "procedures_counts = diagnoses_procedures_df['ICD9_CODE_procedures'].value_counts()\n",
    "\n",
    "k = 100\n",
    "diagnoses_set = set(diagnoses_counts.keys()[:k])\n",
    "procedures_set = set(procedures_counts.keys()[:k])\n",
    "\n",
    "diagnoses_procedures_df = diagnoses_procedures_df[diagnoses_procedures_df['ICD9_CODE_diagnoses'].isin(diagnoses_set) \n",
    "                                                        | diagnoses_procedures_df['ICD9_CODE_procedures'].isin(procedures_set)]\n",
    "diagnoses_procedures_df.to_csv('data/MIMIC3database/processed/ICD9_diagnoses_procedures_mimic_idx_sentences_top_{}.cs'.format(k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting sentences to a single column\n",
    "diagnoses_procedures_df['DIAGNOSES_SENTENCES'] = diagnoses_procedures_df[['0_diagnoses', '1_diagnoses',\n",
    "       '2_diagnoses', '3_diagnoses', '4_diagnoses', '5_diagnoses',\n",
    "       '6_diagnoses', '7_diagnoses', '8_diagnoses', '9_diagnoses',\n",
    "       '10_diagnoses', '11_diagnoses', '12_diagnoses', '13_diagnoses',\n",
    "       '14_diagnoses', '15_diagnoses', '16_diagnoses', '17_diagnoses',\n",
    "       '18_diagnoses', '19_diagnoses', '20_diagnoses', '21_diagnoses', '22',\n",
    "       '23', '24', '25', '26', '27', '28', '29', '30', '31']].values.tolist()\n",
    "\n",
    "diagnoses_procedures_df['PROCEDURES_SENTENCES'] = diagnoses_procedures_df[\n",
    "    ['0_procedures', '1_procedures', '2_procedures', '3_procedures',\n",
    "       '4_procedures', '5_procedures', '6_procedures', '7_procedures',\n",
    "       '8_procedures', '9_procedures', '10_procedures', '11_procedures',\n",
    "       '12_procedures', '13_procedures', '14_procedures', '15_procedures',\n",
    "       '16_procedures', '17_procedures', '18_procedures', '19_procedures',\n",
    "       '20_procedures', '21_procedures']].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = list(diagnoses_procedures_df.groupby(['SUBJECT_ID']))\n",
    "data = [(subject_id, list(subject_data.groupby(['HADM_ID', 'ADMITTIME']))) for subject_id, subject_data in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = []\n",
    "for _, subject in data:\n",
    "    series = []\n",
    "    for _, timestep in subject:\n",
    "        timestep = timestep[timestep['ICD9_CODE_diagnoses'].isin(diagnoses_set)\n",
    "                           | timestep['ICD9_CODE_procedures'].isin(procedures_set)]\n",
    "        if len(timestep) > 0:\n",
    "            series.append((np.stack(timestep['DIAGNOSES_SENTENCES'],axis=0), np.stack(timestep['PROCEDURES_SENTENCES'],axis=0)))\n",
    "        #for _, timestep in timesteps:\n",
    "        #    print(timestep)\n",
    "    if len(series) > 0:\n",
    "        inputs.append(series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnoses_idx_map = {}\n",
    "\n",
    "for i, code in enumerate(diagnoses_counts.keys()[:k]):\n",
    "    diagnoses_idx_map[code] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnoses_counts.keys()[:k]\n",
    "outputs = []\n",
    "\n",
    "def get_onehot_vector(indices, k):\n",
    "    prediction = np.zeros(k, dtype='float32')\n",
    "    prediction[indices] = 1\n",
    "    return prediction\n",
    "\n",
    "for _, subject in data:\n",
    "    series = []\n",
    "    for _, timestep in subject:\n",
    "        indices = [diagnoses_idx_map[key] for key in timestep['ICD9_CODE_diagnoses'] \\\n",
    "                  if key in diagnoses_set]\n",
    "        series.append(get_onehot_vector(indices, k))\n",
    "    outputs.append(np.array(series))\n",
    "#outputs = list(map(get_key, outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_len = 3\n",
    "\n",
    "all_inputs = inputs\n",
    "all_outputs = outputs\n",
    "\n",
    "inputs = list(filter(lambda x : len(x) >= min_len, all_inputs))\n",
    "outputs = list(filter(lambda x: len(x) >= min_len, all_outputs))\n",
    "\n",
    "n_seq = len(inputs)\n",
    "\n",
    "split = int(n_seq*0.8)\n",
    "train_inputs = inputs[:split]\n",
    "train_outputs =  outputs[:split]\n",
    "\n",
    "test_inputs = inputs[split:n_seq]\n",
    "test_outputs = outputs[split:n_seq]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_embedding = pd.read_csv('data/embeddings/w2vModel1Gram9Jan2019_mimic_only.txt', index_col=0)\n",
    "word_embedding.drop('0',axis=1,inplace=True)\n",
    "word_embedding = torch.tensor(word_embedding.astype('float32').values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MODEL DEFINITION\n",
    "from src.model.mimic_deepset import SetSequenceModel\n",
    "\n",
    "n_diagnoses = k\n",
    "hidden_dim=[1000,100]\n",
    "n_epoch = 10\n",
    "freeze_embedding = True\n",
    "\n",
    "_LOGGER.handlers = [\n",
    "    h for h in _LOGGER.handlers if not isinstance(h, logging.StreamHandler)]\n",
    "model_name = \"diagnoses_classifier_top_{}_{}hd_{}\".format(k, hidden_dim, n_epoch)\n",
    "fh = logging.FileHandler('logs/MIMIC3/{}.log'.format(model_name))\n",
    "fh.setLevel(logging.DEBUG)\n",
    "_LOGGER.addHandler(fh)\n",
    "\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "model = SetSequenceModel(hidden_dim=hidden_dim, n_class=n_diagnoses,embedding=word_embedding, freeze_embedding=freeze_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:MIMIC_seq_model:Validation Loss: 0.692812442779541\n"
     ]
    }
   ],
   "source": [
    "test_losses = []\n",
    "for sequence, target in zip(test_inputs, test_outputs):\n",
    "    model.hidden = model.init_hidden()\n",
    "    logits = model(sequence)\n",
    "    \n",
    "    loss = loss_fn(logits[:-1],torch.tensor(target[1:]))\n",
    "    test_losses.append(loss.data)\n",
    "_LOGGER.info(\"Validation Loss: {}\".format(np.mean(test_losses)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:MIMIC_seq_model:epoch 0: 0.21778380870819092\n",
      "INFO:MIMIC_seq_model:epoch 1: 0.17794924974441528\n",
      "INFO:MIMIC_seq_model:epoch 2: 0.15421701967716217\n",
      "INFO:MIMIC_seq_model:epoch 3: 0.13635408878326416\n",
      "INFO:MIMIC_seq_model:epoch 4: 0.1224445030093193\n",
      "INFO:MIMIC_seq_model:epoch 5: 0.11081551015377045\n",
      "INFO:MIMIC_seq_model:epoch 6: 0.09973505884408951\n",
      "INFO:MIMIC_seq_model:epoch 7: 0.09157151728868484\n",
      "INFO:MIMIC_seq_model:epoch 8: 0.08456550538539886\n",
      "INFO:MIMIC_seq_model:epoch 9: 0.07857616990804672\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=.9)\n",
    "losses = []\n",
    "\n",
    "\n",
    "for epoch in range(n_epoch):\n",
    "    curr_losses = []\n",
    "    for sequence, target in zip(train_inputs,\n",
    "                                train_outputs):\n",
    "        model.zero_grad()\n",
    "        model.hidden = model.init_hidden()\n",
    "        \n",
    "        logits = model(sequence)\n",
    "        loss = loss_fn(logits[1:], torch.tensor(target[1:]))\n",
    "        curr_losses.append(loss.data)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    mean_loss = np.mean(curr_losses)\n",
    "    losses.append(mean_loss)\n",
    "    _LOGGER.info(\"epoch {}: {}\".format(epoch, mean_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:MIMIC_seq_model:final validation Loss: 0.36749565601348877\n"
     ]
    }
   ],
   "source": [
    "test_losses = []\n",
    "for sequence, target in zip(test_inputs, test_outputs):\n",
    "    model.hidden = model.init_hidden()\n",
    "    logits = model(sequence)\n",
    "    loss = loss_fn(logits[:-1],torch.tensor(target[1:]))\n",
    "    test_losses.append(loss.data)\n",
    "_LOGGER.info(\"final validation Loss: {}\".format(np.mean(test_losses)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving model\n",
    "torch.save(model, 'models/MIMIC3/{}.pt'.format(model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('models/MIMIC3/diagnoses_classifier_top_100_[1000, 100]hd_10.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmoid = nn.Sigmoid()\n",
    "test_model_outputs = []\n",
    "all_logits = []\n",
    "predictions = []\n",
    "for sequence, target in zip(test_inputs, test_outputs):\n",
    "    model.hidden = model.init_hidden()\n",
    "    logits = model(sequence)\n",
    "    #loss = loss_fn(logits[:-1],torch.tensor(target[1:]))\n",
    "    #test_losses.append(loss.data)\n",
    "    model_output = sigmoid(logits).detach().numpy()\n",
    "    prediction = model_output > 0.5\n",
    "    prediction = prediction.astype(np.float32)\n",
    "    all_logits.append(logits.detach().numpy())\n",
    "    test_model_outputs.append(model_output)\n",
    "    predictions.append(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.58153254\n"
     ]
    }
   ],
   "source": [
    "#k at\n",
    "from src.utils import precision_at_k\n",
    "k = 1\n",
    "precisions_at_k = []\n",
    "for logit, true_output in zip(all_logits, test_outputs):\n",
    "    precisions_at_k.append(precision_at_k(logit[:-1], true_output[1:], k))\n",
    "\n",
    "print(np.mean(precisions_at_k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confidence interval\n",
    "k = 1\n",
    "n_bootstrap = 1000\n",
    "n_samples = 1000\n",
    "from sklearn.utils import resample\n",
    "from src.utils import precision_at_k\n",
    "\n",
    "bootstrap_ks = []\n",
    "for _ in range(n_bootstrap):\n",
    "    bootstrap_logits, bootstrap_outputs = resample(all_logits, test_outputs, n_samples=n_samples)\n",
    "    precisions_at_k = []\n",
    "    for logit, true_output in zip(bootstrap_logits, bootstrap_outputs):\n",
    "        precisions_at_k.append(precision_at_k(logit[:-1], true_output[1:], k))\n",
    "    bootstrap_ks.append(np.mean(precisions_at_k))\n",
    "bootstrap_ks = bootstrap_ks[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5810486950624776, 0.5824855885755229)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np, scipy.stats as st\n",
    "\n",
    "st.t.interval(0.95, len(bootstrap_ks)-1, loc=np.mean(bootstrap_ks), scale=st.sem(bootstrap_ks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  5.,  13.,  58., 181., 239., 251., 160.,  67.,  21.,   4.]),\n",
       " array([0.5427359 , 0.55050105, 0.5582662 , 0.5660314 , 0.5737966 ,\n",
       "        0.5815618 , 0.589327  , 0.59709215, 0.6048573 , 0.6126225 ,\n",
       "        0.6203877 ], dtype=float32),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(bootstrap_ks,bins=20 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "########5 minutes model##########\n",
    "#preprocessing inputs to matrix\n",
    "\n",
    "\n",
    "#logistic regression\n",
    "from src.model.mimic_deepset import FullyConnectedNetworkClassifier\n",
    "\n",
    "model = FullyConnectedNetworkClassifier(100, word_embedding, [1000, 100])\n",
    "loss_fn = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:MIMIC_seq_model:Validation Loss: 0.6941178441047668\n"
     ]
    }
   ],
   "source": [
    "test_losses = []\n",
    "for sequence, target in zip(test_inputs, test_outputs):\n",
    "    logits = model(sequence)\n",
    "    \n",
    "    loss = loss_fn(logits[:-1],torch.tensor(target[1:]))\n",
    "    test_losses.append(loss.data)\n",
    "_LOGGER.info(\"Validation Loss: {}\".format(np.mean(test_losses)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:MIMIC_seq_model:epoch 0: 0.10724962502717972\n",
      "INFO:MIMIC_seq_model:epoch 1: 0.10362500697374344\n",
      "INFO:MIMIC_seq_model:epoch 2: 0.09642152488231659\n",
      "INFO:MIMIC_seq_model:epoch 3: 0.09299089759588242\n",
      "INFO:MIMIC_seq_model:epoch 4: 0.09194406121969223\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=.9)\n",
    "losses = []\n",
    "n_epoch=5\n",
    "\n",
    "for epoch in range(n_epoch):\n",
    "    curr_losses = []\n",
    "    for sequence, target in zip(train_inputs,\n",
    "                                train_outputs):\n",
    "        model.zero_grad()\n",
    "        \n",
    "        logits = model(sequence)\n",
    "        loss = loss_fn(logits[1:], torch.tensor(target[1:]))\n",
    "        curr_losses.append(loss.data)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    mean_loss = np.mean(curr_losses)\n",
    "    losses.append(mean_loss)\n",
    "    _LOGGER.info(\"epoch {}: {}\".format(epoch, mean_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:MIMIC_seq_model:Validation Loss: 0.417359858751297\n"
     ]
    }
   ],
   "source": [
    "test_losses = []\n",
    "for sequence, target in zip(test_inputs, test_outputs):\n",
    "    logits = model(sequence)\n",
    "    \n",
    "    loss = loss_fn(logits[:-1],torch.tensor(target[1:]))\n",
    "    test_losses.append(loss.data)\n",
    "_LOGGER.info(\"Validation Loss: {}\".format(np.mean(test_losses)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmoid = nn.Sigmoid()\n",
    "test_model_outputs = []\n",
    "all_logits = []\n",
    "predictions = []\n",
    "for sequence, target in zip(test_inputs, test_outputs):\n",
    "    logits = model(sequence)\n",
    "    #loss = loss_fn(logits[:-1],torch.tensor(target[1:]))\n",
    "    #test_losses.append(loss.data)\n",
    "    model_output = sigmoid(logits).detach().numpy()\n",
    "    prediction = model_output > 0.5\n",
    "    prediction = prediction.astype(np.float32)\n",
    "    all_logits.append(logits.detach().numpy())\n",
    "    test_model_outputs.append(model_output)\n",
    "    predictions.append(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confidence interval\n",
    "k = 1\n",
    "n_bootstrap = 1000\n",
    "from sklearn.utils import resample\n",
    "from src.utils import precision_at_k\n",
    "\n",
    "precisions_at_k = []\n",
    "for logit, true_output in zip(all_logits, test_outputs):\n",
    "    precisions_at_k.append(precision_at_k(logit[:-1], true_output[1:], k))\n",
    "\n",
    "bootstrapped_paks = [np.mean(resample(precisions_at_k)) for _ in range(n_bootstrap)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5844169880107548, 0.5864697669788692)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np, scipy.stats as st\n",
    "\n",
    "st.t.interval(0.95, len(bootstrapped_paks)-1, loc=np.mean(bootstrapped_paks), scale=st.sem(bootstrap_ks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  4.,   3.,  12.,  19.,  34.,  53., 107., 132., 120., 135., 135.,\n",
       "         84.,  79.,  47.,  17.,  11.,   2.,   3.,   2.,   1.]),\n",
       " array([0.5296049 , 0.535742  , 0.541879  , 0.5480161 , 0.55415314,\n",
       "        0.5602902 , 0.56642723, 0.5725643 , 0.5787014 , 0.5848384 ,\n",
       "        0.59097546, 0.59711254, 0.60324955, 0.6093866 , 0.6155237 ,\n",
       "        0.6216607 , 0.6277978 , 0.63393486, 0.6400719 , 0.64620894,\n",
       "        0.652346  ], dtype=float32),\n",
       " <a list of 20 Patch objects>)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(bootstrapped_paks, bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_flattened = np.concatenate([prediction[:-1] for prediction in predictions]).flatten()\n",
    "true_labels_flattened = np.concatenate([test_output[1:] for test_output in test_outputs]).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[108635,   3874],\n",
       "       [  6650,   3141]])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(true_labels_flattened, predictions_flattened)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepset",
   "language": "python",
   "name": "deepset"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
